{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "accf93c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33432, 10)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = '/Users/jonzimmerman/Desktop/Data Projects/Amtrak/data/'\n",
    "amtrak_df = pd.read_csv(path + 'amtrak_df.csv')\n",
    "amtrak_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04605275",
   "metadata": {},
   "source": [
    "### Little cleanup before getting into everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c583b6",
   "metadata": {},
   "source": [
    "#### 1.) Fix Tomah, WI coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dfaaa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amtrak_df['lat'] = np.where(amtrak_df['abbrev']==\"TOH\",43.985912,amtrak_df['lat'])\n",
    "amtrak_df['lon'] = np.where(amtrak_df['abbrev']==\"TOH\",-90.506204,amtrak_df['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265b85d",
   "metadata": {},
   "source": [
    "#### 2.) Add route data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d63bc3",
   "metadata": {},
   "source": [
    "https://www.railpassengers.org/resources/ridership-statistics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed8da6",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "30ca8626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acela = ['Baltimore, MD','BWI Airport','Back Bay','Boston','Metropark','New Carrollton','New Haven','New London','New Rochelle','New York, NY','Newark, NJ','Philadelphia, PA','Providence, RI','Stamford, CT','Trenton, NJ','Washington, DC','Wilmington, DE','Route 128-Westwood, MA']\n",
    "adirondack = ['Albany, NY', 'Croton', 'Fort Edward-Glens Falls, NY', 'Hudson', 'New York, NY', 'Plattsburgh', 'Port Henry', 'Poughkeepsie', 'Rhinecliff', 'Rouses Point', 'St. Lambert', 'Saratoga Springs', 'Schenectady', 'Ticonderoga', 'Westport', 'Whitehall', 'Yonkers']\n",
    "cascades = ['Albany, OR','Bellingham, WA', 'Centralia', 'Edmonds, WA', 'Eugene, OR', 'Everett, WA','Kelso--Longview','Mount Vernon','Olympia','Oregon City', 'Portland','Salem','Seattle','Stanwood','Tacoma','Tukwila','Vancouver']\n",
    "blue_water = ['Battle Creek','Chicago','Dowagiac','Durand', 'East Lansing', 'Flint', 'Kalamazoo', 'Lapeer','New Buffalo', 'Niles','Port Huron']\n",
    "california_zephyr = ['Burlington','Chicago','Colfax','Creston','Davis','Denver','Elko','Emeryville','Fort Morgan','Fraser-Winter Park','Galesburg','Glenwood Springs','Granby','Grand Junction','Green River','Hastings','Helper','Holdrege','Lincoln','Martinez','McCook','Mount Pleasant','Naperville','Omaha','Osceola','Ottumwa','Princeton, IL','Provo','Reno','Roseville','Sacramento','Salt Lake City','Truckee','Winnemucca']\n",
    "\n",
    "# Create regex patterns for each route\n",
    "acela_pattern = '|'.join(acela)\n",
    "adirondack_pattern = '|'.join(adirondack)\n",
    "cascades_pattern = '|'.join(cascades)\n",
    "blue_water_pattern = '|'.join(blue_water)\n",
    "california_zephyr_pattern = '|'.join(california_zephyr)\n",
    "\n",
    "# Apply np.where with correct scalar choices\n",
    "amtrak_df['acela_route'] = np.where(amtrak_df['station_name'].str.contains(acela_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['adirondack_route'] = np.where(amtrak_df['station_name'].str.contains(adirondack_pattern, case=False, na=False), 1 ,0)\n",
    "amtrak_df['cascades_route'] = np.where(amtrak_df['station_name'].str.contains(cascades_pattern, case=False, na=False), 1 ,0)\n",
    "amtrak_df['blue_water_route'] = np.where(amtrak_df['station_name'].str.contains(blue_water_pattern, case=False, na=False), 1 ,0)\n",
    "amtrak_df['california_zephyr_route'] = np.where(amtrak_df['station_name'].str.contains(california_zephyr_pattern, case=False, na=False), 1 ,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ea38c",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "672aba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_corridor = ['Auburn','Berkeley','Davis','Emeryville','Fairfield','Vacaville','Fremont','Hayward','Martinez','Oakland','Oakland Coliseum','Rocklin','Roseville','Sacramento','San Jose','Santa Clara','Suisun City']\n",
    "capital_limited = ['Alliance','Chicago','Cleveland','Connellsville','Cumberland','Elkhart','Elyria','Harpers Ferry','Martinsburg','Pittsburgh','Rockville','Sandusky','South Bend','Toledo','Washington, DC','Waterloo']\n",
    "cardinal = ['Alderson','Alexandria','Ashland','Baltimore','Charleston','Charlottesville','Chicago','Cincinnati','Clifton Forge','Connersville','Crawfordsville','Culpeper','Dyer','Hinton','Huntington','Indianapolis','Lafayette','Manassas','Maysville','Montgomery','New York','Newark','Philadelphia','Prince','Rensselaer','Portsmouth','Staunton','Thurmond','Trenton','Washington, DC','Sulphur Springs','Wilmington']\n",
    "carl_sandburg = ['Chicago','Galesburg','Kewanee','La Grange','Macomb','Mendota','Naperville','Plano','Princeton, IL','Quincy']\n",
    "carolian = ['Alexandria, VA','Baltimore','Burlington, NC','Cary','Charlotte','Durham','Fredericksburg','Greensboro',\n",
    "            'High Point','Kannapolis','New York','Newark, NJ','NC State Fair','Petersburg','Philadelphia','Quantico',\n",
    "            'Raleigh','Richmond','Rocky Mount','Salisbury','Selma--Smithfield','Trenton','Washington, DC',\n",
    "            'Wilmington, DE','Wilson']\n",
    "\n",
    "\n",
    "capital_corridor_pattern = '|'.join(capital_corridor)\n",
    "capital_limited_pattern = '|'.join(capital_limited)\n",
    "cardinal_pattern = '|'.join(cardinal)\n",
    "carl_sandburg_pattern = '|'.join(carl_sandburg)\n",
    "carolian_pattern = '|'.join(carolian)\n",
    "\n",
    "\n",
    "amtrak_df['capital_corridor_route'] = np.where(amtrak_df['station_name'].str.contains(capital_corridor_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['capital_limited_route'] = np.where(amtrak_df['station_name'].str.contains(capital_limited_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['cardinal_route'] = np.where(amtrak_df['station_name'].str.contains(cardinal_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['carl_sandburg_route'] = np.where(amtrak_df['station_name'].str.contains(carl_sandburg_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['carolian_route'] = np.where(amtrak_df['station_name'].str.contains(carolian_pattern, case=False, na=False), 1 ,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd3880",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "627a0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_of_new_orleans = ['Brookhaven','Carbondale','Centralia, IL','Champaign','Chicago','Effingham','Fulton','Greenwood','Hammond','Hazlehurst','Homewood','Jackson, MS','Kankakee','Marks','Mattoon','McComb','Memphis','New Orleans','Newbern--Dyersburg','Yazoo City']\n",
    "coast_starlight = ['Albany, OR','Burbank','Centralia, WA','Chemult','Chico','Davis','Dunsmuir','Emeryville','Eugene','Kelso-Longview','Klamath Falls','Los Angeles','Martinez','Oakland','Olympia','Oxnard','Paso Robles','Portland','Redding','Sacramento','Salem','Salinas','San Jose','San Luis Obispo','Santa Barbara','Seattle','Simi Valley','Tacoma','Van Nuys','Vancouver']\n",
    "crescent = ['Alexandria','Anniston','Atlanta','Baltimore','BWI Airport','Birmingham','Charlotte','Charlottesville','Clemson','Culpeper','Danville','Gainesville','Gastonia','Greensboro','Greenville','Hattiesburg','High Point','Laurel','Lynchburg','Manassas','Meridian','Metropark','New Orleans','New York','Newark','Philadelphia','Picayune','Salisbury','Slidell','Spartanburg','Toccoa','Trenton','Tuscaloosa','Washington, DC','Wilmington, DE']\n",
    "downeaster = ['Boston-North','Brunswick','Dover','Durham-UNH','Exeter','Freeport','Haverhill','Old Orchard Beach','Portland','Saco','Wells','Woburn']\n",
    "empire_builder = ['Bingen','White Salmon','Browning','Chicago','Columbus','Cut Bank','Detroit Lakes','Devils Lake','East Glacier','Edmonds','Ephrata','Essex, MT','Everett','Fargo','Glasgow','Glenview','Grand Forks','Havre','La Crosse','Leavenworth','Libby','Malta','Milwaukee','Minot','Pasco','Portage','Portland','Red Wing','Rugby','St. Cloud','St. Paul','Sandpoint','Seattle','Shelby','Spokane','Stanley','Staples','Tomah','Vancouver','Wenatchee','West Glacier','Whitefish','Williston','Winona','Wisconsin Dells','Wishram','Wolf Point']\n",
    "\n",
    "city_of_new_orleans_pattern = '|'.join(city_of_new_orleans)\n",
    "coast_starlight_pattern = '|'.join(coast_starlight)\n",
    "crescent_pattern = '|'.join(crescent)\n",
    "downeaster_pattern = '|'.join(downeaster)\n",
    "empire_builder_pattern = '|'.join(empire_builder)\n",
    "\n",
    "amtrak_df['city_of_new_orleans_route'] = np.where(amtrak_df['station_name'].str.contains(city_of_new_orleans_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['coast_starlight_route'] = np.where(amtrak_df['station_name'].str.contains(coast_starlight_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['crescent_route'] = np.where(amtrak_df['station_name'].str.contains(crescent_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['downeaster_route'] = np.where(amtrak_df['station_name'].str.contains(downeaster_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['empire_builder_route'] = np.where(amtrak_df['station_name'].str.contains(empire_builder_pattern, case=False, na=False), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa1604",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6ccda1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethan_allen = ['Albany, NY','Burlington, VT','Castleton','Croton-Harmon','Fort Edward','Hudson','Middlebury','New York','Poughkeepsie','Rhinecliff','Rutland','Saratoga Springs','Schenectady','Vergennes','Yonkers']\n",
    "heartland_flyer = ['Ardmore, OK','Dallas','Fort Worth','Gainesville','Norman','Oklahoma City','Pauls Valley','Purcell']\n",
    "hiawatha = ['Chicago','Glenview','Milwaukee','Milwaukee Airport','Sturtevant']\n",
    "illini_saluki = ['Carbondale','Centralia, IL','Champaign','Chicago','Du Quoin','Effingham',\n",
    "                 'Gilman','Homewood','Kankakee','Mattoon','Rantoul']\n",
    "keystone = ['Ardmore, PA','Coatesville','Downingtown','Elizabethtown','Exton','Harrisburg',\n",
    "            'Lancaster','Metropark','Middletown','Mount Joy','New Brunswick','New York',\n",
    "            'Newark','Newark-EWR','Paoli','Parkesburg','Philadelphia','Princeton Jct.','Trenton']\n",
    "\n",
    "ethan_allen_pattern = '|'.join(ethan_allen)\n",
    "heartland_flyer_pattern = '|'.join(heartland_flyer)\n",
    "hiawatha_pattern = '|'.join(hiawatha)\n",
    "illini_saluki_pattern = '|'.join(illini_saluki)\n",
    "keystone_pattern = '|'.join(keystone)\n",
    "\n",
    "\n",
    "amtrak_df['ethan_allen_route'] = np.where(amtrak_df['station_name'].str.contains(ethan_allen_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['heartland_flyer_route'] = np.where(amtrak_df['station_name'].str.contains(heartland_flyer_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['hiawatha_route'] = np.where(amtrak_df['station_name'].str.contains(hiawatha_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['illini_saluki_route'] = np.where(amtrak_df['station_name'].str.contains(illini_saluki_pattern, case=False, na=False), 1,0)\n",
    "amtrak_df['keystone_route'] = np.where(amtrak_df['station_name'].str.contains(keystone_pattern, case=False, na=False), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc10f20",
   "metadata": {},
   "source": [
    "### Inspect each route to make sure correct stations are captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c99225c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ardmore, PA',\n",
       " 'Coatesville, PA',\n",
       " 'Downingtown, PA',\n",
       " 'Elizabethtown, PA',\n",
       " 'Exton, PA',\n",
       " 'Metropark-Iselin, NJ',\n",
       " 'Middletown, PA',\n",
       " 'Mount Joy, PA',\n",
       " 'New Brunswick, NJ',\n",
       " 'New York, NY',\n",
       " 'Newark, DE',\n",
       " 'Newark, NJ',\n",
       " 'Newark-Liberty, NJ',\n",
       " 'Parkesburg, PA',\n",
       " 'Philadelphia, PA',\n",
       " 'Princeton Jct, NJ',\n",
       " 'Trenton, NJ']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect = amtrak_df[amtrak_df['keystone_route']==1]\n",
    "inspect['station_name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "00a3fd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albuquerque, NM']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = amtrak_df[amtrak_df['station_name'].str.contains(\"q\")]\n",
    "test['station_name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb81a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
